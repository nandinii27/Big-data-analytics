{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "784bc951",
   "metadata": {},
   "source": [
    "# NANDINI GANTAYAT \n",
    "\n",
    "**Statistical & Machine Learning Individual project**  \n",
    "**Prof.Minh Phan**   \n",
    "\n",
    "IESEG School of Management  \n",
    "MSc in Big Data Analytics for Business"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5fc9f2",
   "metadata": {},
   "source": [
    "# Project Objective  \n",
    "(1) the understanding of machine learning mechanism   \n",
    "(2) the ability to setup a machine learning pipeline.  \n",
    "\n",
    "Bank Telemarketing Outcome Prediction  \n",
    "Predict if the client will subscribe a term deposit after a bank telemarketing campaign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "8a88b912",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install boruta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32df6630",
   "metadata": {},
   "source": [
    "# INITIATION - Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "4385b6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data processing and exploration\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import plotly.graph_objects as go\n",
    "import pickle\n",
    "\n",
    "#Data preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, KBinsDiscretizer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import mutual_info_classif, VarianceThreshold\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Modeling\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.feature_selection import f_classif, RFE\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "import random\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "from scipy.stats import kendalltau, pearsonr, spearmanr\n",
    "from sklearn.model_selection import train_test_split\n",
    "from boruta import BorutaPy\n",
    "\n",
    "# Experimental setup\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_validate, cross_val_score, GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "#\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fec3166",
   "metadata": {},
   "source": [
    "**Reading the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "a76411aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bank=pd.read_csv(\"C:/Users/ngantayat1/Downloads/SML_INDIVIDUAL_PROJECT/Dataset_Bank Marketing_revised (1)/bank_mkt_train.csv\",low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5f45fe",
   "metadata": {},
   "source": [
    "# Data cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9872c0c9",
   "metadata": {},
   "source": [
    "**Exploratory data analysis and data summary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "2c2637a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>subscribe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29925</td>\n",
       "      <td>42</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.9y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jul</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.918</td>\n",
       "      <td>-42.7</td>\n",
       "      <td>4.968</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37529</td>\n",
       "      <td>35</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>jun</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>94.465</td>\n",
       "      <td>-41.8</td>\n",
       "      <td>4.960</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2757</td>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.9y</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>may</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>92.893</td>\n",
       "      <td>-46.2</td>\n",
       "      <td>1.264</td>\n",
       "      <td>5099.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642</td>\n",
       "      <td>45</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>apr</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>93.075</td>\n",
       "      <td>-47.1</td>\n",
       "      <td>1.453</td>\n",
       "      <td>5099.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14183</td>\n",
       "      <td>45</td>\n",
       "      <td>unknown</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.859</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15180</td>\n",
       "      <td>38</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.858</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>27168</td>\n",
       "      <td>33</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>apr</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>failure</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>93.075</td>\n",
       "      <td>-47.1</td>\n",
       "      <td>1.405</td>\n",
       "      <td>5099.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9097</td>\n",
       "      <td>38</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>single</td>\n",
       "      <td>basic.9y</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>30538</td>\n",
       "      <td>29</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>single</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>may</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>failure</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>92.893</td>\n",
       "      <td>-46.2</td>\n",
       "      <td>1.250</td>\n",
       "      <td>5099.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>28981</td>\n",
       "      <td>34</td>\n",
       "      <td>admin.</td>\n",
       "      <td>divorced</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.444</td>\n",
       "      <td>-36.1</td>\n",
       "      <td>4.965</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   client_id  age          job   marital            education  default  \\\n",
       "0      29925   42   management   married             basic.9y       no   \n",
       "1      37529   35   unemployed   married    university.degree       no   \n",
       "2       2757   44   technician   married             basic.9y       no   \n",
       "3       9642   45     services   married          high.school       no   \n",
       "4      14183   45      unknown   married              unknown  unknown   \n",
       "5      15180   38   technician   married  professional.course       no   \n",
       "6      27168   33   technician   married  professional.course       no   \n",
       "7       9097   38  blue-collar    single             basic.9y  unknown   \n",
       "8      30538   29  blue-collar    single              unknown       no   \n",
       "9      28981   34       admin.  divorced    university.degree       no   \n",
       "\n",
       "   housing     loan    contact month  ... campaign  pdays  previous  \\\n",
       "0       no       no   cellular   jul  ...        1    999         0   \n",
       "1      yes       no  telephone   jun  ...        4    999         0   \n",
       "2      yes      yes   cellular   may  ...        1    999         0   \n",
       "3      yes       no   cellular   apr  ...        1    999         0   \n",
       "4  unknown  unknown  telephone   may  ...        1    999         0   \n",
       "5       no       no  telephone   may  ...        2    999         0   \n",
       "6       no      yes   cellular   apr  ...        1    999         1   \n",
       "7      yes       no  telephone   may  ...        1    999         0   \n",
       "8      yes       no   cellular   may  ...        1    999         1   \n",
       "9      yes      yes   cellular   aug  ...        1    999         0   \n",
       "\n",
       "      poutcome emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  \\\n",
       "0  nonexistent          1.4          93.918          -42.7      4.968   \n",
       "1  nonexistent          1.4          94.465          -41.8      4.960   \n",
       "2  nonexistent         -1.8          92.893          -46.2      1.264   \n",
       "3  nonexistent         -1.8          93.075          -47.1      1.453   \n",
       "4  nonexistent          1.1          93.994          -36.4      4.859   \n",
       "5  nonexistent          1.1          93.994          -36.4      4.858   \n",
       "6      failure         -1.8          93.075          -47.1      1.405   \n",
       "7  nonexistent          1.1          93.994          -36.4      4.857   \n",
       "8      failure         -1.8          92.893          -46.2      1.250   \n",
       "9  nonexistent          1.4          93.444          -36.1      4.965   \n",
       "\n",
       "   nr.employed  subscribe  \n",
       "0       5228.1          0  \n",
       "1       5228.1          0  \n",
       "2       5099.1          0  \n",
       "3       5099.1          0  \n",
       "4       5191.0          0  \n",
       "5       5191.0          0  \n",
       "6       5099.1          1  \n",
       "7       5191.0          0  \n",
       "8       5099.1          0  \n",
       "9       5228.1          0  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bank.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "c2df2669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 21 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   client_id       20000 non-null  int64  \n",
      " 1   age             20000 non-null  int64  \n",
      " 2   job             20000 non-null  object \n",
      " 3   marital         20000 non-null  object \n",
      " 4   education       20000 non-null  object \n",
      " 5   default         20000 non-null  object \n",
      " 6   housing         20000 non-null  object \n",
      " 7   loan            20000 non-null  object \n",
      " 8   contact         20000 non-null  object \n",
      " 9   month           20000 non-null  object \n",
      " 10  day_of_week     20000 non-null  object \n",
      " 11  campaign        20000 non-null  int64  \n",
      " 12  pdays           20000 non-null  int64  \n",
      " 13  previous        20000 non-null  int64  \n",
      " 14  poutcome        20000 non-null  object \n",
      " 15  emp.var.rate    20000 non-null  float64\n",
      " 16  cons.price.idx  20000 non-null  float64\n",
      " 17  cons.conf.idx   20000 non-null  float64\n",
      " 18  euribor3m       20000 non-null  float64\n",
      " 19  nr.employed     20000 non-null  float64\n",
      " 20  subscribe       20000 non-null  int64  \n",
      "dtypes: float64(5), int64(6), object(10)\n",
      "memory usage: 3.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_bank.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "b7452e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "object     10\n",
       "int64       6\n",
       "float64     5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bank.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "c39b2bdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 21)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bank.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "7136938f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "client_id         0\n",
       "age               0\n",
       "job               0\n",
       "marital           0\n",
       "education         0\n",
       "default           0\n",
       "housing           0\n",
       "loan              0\n",
       "contact           0\n",
       "month             0\n",
       "day_of_week       0\n",
       "campaign          0\n",
       "pdays             0\n",
       "previous          0\n",
       "poutcome          0\n",
       "emp.var.rate      0\n",
       "cons.price.idx    0\n",
       "cons.conf.idx     0\n",
       "euribor3m         0\n",
       "nr.employed       0\n",
       "subscribe         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bank.isna().sum()  #no null values found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "29713f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>age</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>subscribe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.00000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>20683.031650</td>\n",
       "      <td>40.052000</td>\n",
       "      <td>2.58040</td>\n",
       "      <td>961.164400</td>\n",
       "      <td>0.171400</td>\n",
       "      <td>0.088100</td>\n",
       "      <td>93.577232</td>\n",
       "      <td>-40.472955</td>\n",
       "      <td>3.631806</td>\n",
       "      <td>5167.377640</td>\n",
       "      <td>0.113550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11898.274235</td>\n",
       "      <td>10.412877</td>\n",
       "      <td>2.79065</td>\n",
       "      <td>190.115383</td>\n",
       "      <td>0.493897</td>\n",
       "      <td>1.573281</td>\n",
       "      <td>0.579869</td>\n",
       "      <td>4.621674</td>\n",
       "      <td>1.731216</td>\n",
       "      <td>72.226178</td>\n",
       "      <td>0.317272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.400000</td>\n",
       "      <td>92.201000</td>\n",
       "      <td>-50.800000</td>\n",
       "      <td>0.634000</td>\n",
       "      <td>4963.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10311.750000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.800000</td>\n",
       "      <td>93.075000</td>\n",
       "      <td>-42.700000</td>\n",
       "      <td>1.344000</td>\n",
       "      <td>5099.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>20761.500000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>93.798000</td>\n",
       "      <td>-41.800000</td>\n",
       "      <td>4.857000</td>\n",
       "      <td>5191.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>30993.250000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>93.994000</td>\n",
       "      <td>-36.400000</td>\n",
       "      <td>4.961000</td>\n",
       "      <td>5228.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>41188.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>56.00000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>94.767000</td>\n",
       "      <td>-26.900000</td>\n",
       "      <td>5.045000</td>\n",
       "      <td>5228.100000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          client_id           age     campaign         pdays      previous  \\\n",
       "count  20000.000000  20000.000000  20000.00000  20000.000000  20000.000000   \n",
       "mean   20683.031650     40.052000      2.58040    961.164400      0.171400   \n",
       "std    11898.274235     10.412877      2.79065    190.115383      0.493897   \n",
       "min        2.000000     17.000000      1.00000      0.000000      0.000000   \n",
       "25%    10311.750000     32.000000      1.00000    999.000000      0.000000   \n",
       "50%    20761.500000     38.000000      2.00000    999.000000      0.000000   \n",
       "75%    30993.250000     47.000000      3.00000    999.000000      0.000000   \n",
       "max    41188.000000     98.000000     56.00000    999.000000      6.000000   \n",
       "\n",
       "       emp.var.rate  cons.price.idx  cons.conf.idx     euribor3m  \\\n",
       "count  20000.000000    20000.000000   20000.000000  20000.000000   \n",
       "mean       0.088100       93.577232     -40.472955      3.631806   \n",
       "std        1.573281        0.579869       4.621674      1.731216   \n",
       "min       -3.400000       92.201000     -50.800000      0.634000   \n",
       "25%       -1.800000       93.075000     -42.700000      1.344000   \n",
       "50%        1.100000       93.798000     -41.800000      4.857000   \n",
       "75%        1.400000       93.994000     -36.400000      4.961000   \n",
       "max        1.400000       94.767000     -26.900000      5.045000   \n",
       "\n",
       "        nr.employed     subscribe  \n",
       "count  20000.000000  20000.000000  \n",
       "mean    5167.377640      0.113550  \n",
       "std       72.226178      0.317272  \n",
       "min     4963.600000      0.000000  \n",
       "25%     5099.100000      0.000000  \n",
       "50%     5191.000000      0.000000  \n",
       "75%     5228.100000      0.000000  \n",
       "max     5228.100000      1.000000  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bank.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "84a33ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of clients: 20000\n"
     ]
    }
   ],
   "source": [
    "total_clients = df_bank['client_id'].count()\n",
    "print(f'Total number of clients: {total_clients}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "addda854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DataFrame train has 20000 unique client IDs.\n"
     ]
    }
   ],
   "source": [
    "unique_clients = df_bank['client_id'].nunique()\n",
    "print(f'The DataFrame train has {unique_clients} unique client IDs.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11979bcd",
   "metadata": {},
   "source": [
    "**Creating a list of columns names for managing variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "a7b72bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['client_id',\n",
       " 'age',\n",
       " 'job',\n",
       " 'marital',\n",
       " 'education',\n",
       " 'default',\n",
       " 'housing',\n",
       " 'loan',\n",
       " 'contact',\n",
       " 'month',\n",
       " 'day_of_week',\n",
       " 'campaign',\n",
       " 'pdays',\n",
       " 'previous',\n",
       " 'poutcome',\n",
       " 'emp.var.rate',\n",
       " 'cons.price.idx',\n",
       " 'cons.conf.idx',\n",
       " 'euribor3m',\n",
       " 'nr.employed',\n",
       " 'subscribe']"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bank.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "9040b776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of numerical and catergorical variables present in the df\n",
    "num_vars = ['age', 'campaign', 'pdays', 'previous',\n",
    "            'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed']\n",
    "\n",
    "\n",
    "cat_vars = ['job', 'marital', 'education', 'default', 'housing', 'loan',\n",
    "            'contact', 'month', 'day_of_week',\n",
    "            'poutcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "b6db8bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data - # NA of num vars: 0\n",
      "Data - # NA of cat vars: 0\n"
     ]
    }
   ],
   "source": [
    "print('Data - # NA of num vars:', df_bank[num_vars].isna().sum().sum())\n",
    "print('Data - # NA of cat vars:', df_bank[cat_vars].isna().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "e564bb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_var = [\"client_id\"]  # ID\n",
    "target_var = [\"subscribe\"]  #Binary Target variable\n",
    "predictors = [v for v in df_bank.columns if v not in id_var + target_var]\n",
    "\n",
    "# checking the list of variables\n",
    "assert(len(predictors) == len(num_vars) + len(cat_vars))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdd93fb",
   "metadata": {},
   "source": [
    "**Checking the target variable distribution to see if there is a class imbalance** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "4b7fdecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subscribe\n",
      "0            17729\n",
      "1             2271\n",
      "dtype: int64\n",
      "subscribe\n",
      "0            0.88645\n",
      "1            0.11355\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df_bank[target_var].value_counts())   # number wise\n",
    "\n",
    "print(df_bank[target_var].value_counts(normalize=True))  # percentage wise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdb2757",
   "metadata": {},
   "source": [
    "**Check and correct data error - Outliers in numerical variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "d00133c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age has outliers : 182 [ 0.91 % ]\n",
      "campaign has outliers : 427 [ 2.14 % ]\n",
      "pdays has outliers : 762 [ 3.81 % ]\n",
      "previous has outliers : 522 [ 2.61 % ]\n"
     ]
    }
   ],
   "source": [
    "# Check the outliers on train, test\n",
    "for v in num_vars:\n",
    "    # Calculate the boundaries on train [mean-3*sd, mean+3*sd]\n",
    "    mu = np.mean(df_bank[v])\n",
    "    sd = np.std(df_bank[v])\n",
    "    lower = mu - 3*sd\n",
    "    upper = mu + 3*sd\n",
    "    # Check outliers using the boundaries\n",
    "    data_out = (df_bank[v] < lower) | (df_bank[v] > upper)\n",
    "    if np.sum(data_out)  > 0:\n",
    "        print(v, \"has outliers :\",\n",
    "              np.sum(data_out), \"[\", np.round(100*np.mean(data_out), 2), \"% ]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a8a9bf",
   "metadata": {},
   "source": [
    "**Encode categorical variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "e799262d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables as integer values\n",
    "# Categorical variables in any format will be converted to string\n",
    "\n",
    "enc = OrdinalEncoder()\n",
    "enc.fit(pd.concat([df_bank[cat_vars].astype(str), df_bank[cat_vars].astype(str)], axis=0))\n",
    "df_bank[cat_vars] = enc.transform(df_bank[cat_vars].astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c247ce91",
   "metadata": {},
   "source": [
    "**Finalize the processed data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "afa308d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# id_var [ 1 ] : ['client_id']\n",
      "# num_vars [ 9 ] : ['age', 'campaign', 'pdays', 'previous', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed']\n",
      "# cat_vars [ 10 ] : ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'poutcome']\n",
      "# target_var [ 1 ] : ['subscribe']\n"
     ]
    }
   ],
   "source": [
    "# Print out the final variables\n",
    "print(\"# id_var [\", len(id_var), \"] :\", id_var)\n",
    "print(\"# num_vars [\", len(num_vars), \"] :\", num_vars)\n",
    "print(\"# cat_vars [\", len(cat_vars), \"] :\", cat_vars)\n",
    "print(\"# target_var [\", len(target_var), \"] :\", target_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "29b44650",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bank = df_bank[id_var + num_vars + cat_vars + target_var]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abef58e2",
   "metadata": {},
   "source": [
    "**Train Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "a677feee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create train test split\n",
    "train, test = train_test_split(df_bank, test_size=0.2, random_state=42, stratify=df_bank.subscribe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "c82cfcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "68d58531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape :  (16000, 21)\n",
      "Test Shape :  (4000, 21)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Shape : \",train.shape)\n",
    "print(\"Test Shape : \", test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c5224a",
   "metadata": {},
   "source": [
    "# Feature Engineering  \n",
    "   \n",
    "   **VALUE TRANSFORMATION (num, cat => cat)**  \n",
    "1) Add polynomial terms for numerical variables   \n",
    "2) Remapping categorical variables - Decision tree–based remapping  \n",
    "3) Binning and dicretization     \n",
    "\n",
    "   **VALUE REPRESENTATION (cat => num)**  \n",
    "1) Categorical variable: Dummy coding  \n",
    "2) Categorical variable: Incidence replacement  \n",
    "3) Categorical variable: Weight of Evidence (WoE) conversion  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517db428",
   "metadata": {},
   "source": [
    "**Mutual information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c937f44e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45360284",
   "metadata": {},
   "source": [
    "**adding the polynomial terms (degree=3) for a num variable as it increases the LR model performance.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "b606638c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable age AUC vs. AUC poly: 0.49143225824849673 --> 0.6019409974388598\n",
      "Variable cons.conf.idx AUC vs. AUC poly: 0.5368042530608538 --> 0.5887988392474264\n"
     ]
    }
   ],
   "source": [
    "enable_num_poly = True \n",
    "\n",
    "if enable_num_poly:\n",
    "    for v in num_vars:\n",
    "        # Setup the LR model\n",
    "        cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "        model = LogisticRegression(max_iter=200)\n",
    "        parameters = {}\n",
    "        clf = GridSearchCV(model, parameters, scoring=\"roc_auc\", n_jobs=-1, cv=cv, verbose=0)\n",
    "        \n",
    "        # Fit the LR model for 1 numerical variable\n",
    "        clf.fit(train[[v]], train[target_var].squeeze())\n",
    "        clf_num_score = clf.best_score_\n",
    "        \n",
    "        # Fit the LR model for 1 numerical variable + it polynomial degree = 3\n",
    "        poly = PolynomialFeatures(degree=3, include_bias=False)\n",
    "        poly.fit(train[[v]])\n",
    "        clf.fit(poly.transform(train[[v]]), train[target_var].squeeze())\n",
    "        clf_poly_score = clf.best_score_\n",
    "        \n",
    "        # Add the polynomial terms to train, test\n",
    "        if (clf_poly_score > 0.5) & (clf_poly_score - clf_num_score > 0.05):\n",
    "            print('Variable', v, 'AUC vs. AUC poly:', clf_num_score, '-->', clf_poly_score)\n",
    "            poly_vars = [v_poly.replace('x0', v) for v_poly in poly.get_feature_names()[1:]]\n",
    "            num_vars = num_vars + poly_vars\n",
    "            train[poly_vars] = pd.DataFrame(poly.transform(train[[v]])[:, 1:], columns=poly_vars)\n",
    "            test[poly_vars] = pd.DataFrame(poly.transform(test[[v]])[:, 1:], columns=poly_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8221dac",
   "metadata": {},
   "source": [
    "**Value transformation (num, cat => cat)**  \n",
    "\n",
    "Steps included in value transformation  \n",
    "\n",
    "For categorical variables : remapping  \n",
    "For continuous variables : discretization or binning  \n",
    "\n",
    "1. Test the value transformation on one variable  \n",
    "2. Check the AUC and new number of categories formed  \n",
    "3. Apply the value transformation on all variables if the AUC > 0.5 and number of new categories > 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "d20931b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of variables to track the value transformation process\n",
    "trans_vars = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27f99d8",
   "metadata": {},
   "source": [
    " **Remapping categorical variables - Decision tree–based remapping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "171e331d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best AUC: 0.60597557748228\n",
      "Best params: {'min_samples_leaf': 160}\n",
      "Number of leaves: 11\n"
     ]
    }
   ],
   "source": [
    "# Select a cat variable\n",
    "v = \"job\"\n",
    "\n",
    "# Find the best decision tree\n",
    "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "model = DecisionTreeClassifier()\n",
    "parameters = {'min_samples_leaf':(train.shape[0]*np.array([0.01, 0.025, 0.05, 0.1, 0.25, 0.5])).astype(int)}\n",
    "clf = GridSearchCV(model, parameters, scoring=\"roc_auc\", n_jobs=-1, cv=cv, verbose=0)\n",
    "clf.fit(train[[v]], train[target_var])\n",
    "print(\"Best AUC:\", clf.best_score_)\n",
    "print(\"Best params:\", clf.best_params_)\n",
    "print(\"Number of leaves:\", clf.best_estimator_.get_n_leaves())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "155cef16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# original categories: 12\n",
      "# new remapped categories: 11 {2, 4, 6, 7, 10, 11, 14, 15, 17, 19, 20}\n"
     ]
    }
   ],
   "source": [
    "# Grouping the categories into new categories (leaves) using Decision Tree\n",
    "# Here, we use the decision path, the last node is the new segment of an observation\n",
    "remap_v = [np.nonzero(r)[0].max() for r in clf.best_estimator_.decision_path(train[[v]]).toarray()]\n",
    "\n",
    "print(\"# original categories:\", train[[v]].nunique().values[0])\n",
    "print(\"# new remapped categories:\", len(set(remap_v)), set(remap_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "981d4edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remapping variable job from 12 to 11 categories\n",
      "Remapping variable marital from 4 to 3 categories\n",
      "Remapping variable education from 8 to 6 categories\n",
      "Remapping variable default from 3 to 2 categories\n",
      "Remapping variable housing from 3 to 2 categories\n",
      "Remapping variable contact from 2 to 2 categories\n",
      "Remapping variable month from 10 to 9 categories\n",
      "Remapping variable day_of_week from 5 to 2 categories\n",
      "Remapping variable poutcome from 3 to 3 categories\n"
     ]
    }
   ],
   "source": [
    "enable_trans_cat_dt=True\n",
    "\n",
    "if enable_trans_cat_dt:\n",
    "    for v in cat_vars:\n",
    "        # Find the best decision tree using CV\n",
    "        cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "        model = DecisionTreeClassifier()\n",
    "        parameters = {'min_samples_leaf':(train.shape[0]*np.array([0.01, 0.025, 0.05, 0.1, 0.25, 0.5])).astype(int)}\n",
    "        clf = GridSearchCV(model, parameters, scoring=\"roc_auc\", n_jobs=-1, cv=cv, verbose=0)\n",
    "        clf.fit(train[[v]], train[target_var])\n",
    "        # Remap the variable on train, test\n",
    "        if (clf.best_score_ > 0.5) & (clf.best_estimator_.get_n_leaves() > 1):\n",
    "            print(\"Remapping variable\", v,\n",
    "                  \"from\", train[[v]].nunique().values[0],\n",
    "                  \"to\", clf.best_estimator_.get_n_leaves(), \"categories\")\n",
    "            remap_var = v + '_remap'\n",
    "            trans_vars.append(remap_var)\n",
    "            train[remap_var] = [np.nonzero(r)[0].max() for r in clf.best_estimator_.decision_path(train[[v]]).toarray()]\n",
    "            test[remap_var] = [np.nonzero(r)[0].max() for r in clf.best_estimator_.decision_path(test[[v]]).toarray()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1b0ea6",
   "metadata": {},
   "source": [
    "**Remapping continuous variable - Discretization and Binning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "cb3461af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best AUC: 0.5974011307218652\n",
      "Best params: {'min_samples_leaf': 400}\n",
      "Number of leaves: 26\n"
     ]
    }
   ],
   "source": [
    "# Select a num variable\n",
    "v = \"age\"\n",
    "\n",
    "# Find the best decision tree\n",
    "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "model = DecisionTreeClassifier()\n",
    "parameters = {'min_samples_leaf':(train.shape[0]*np.array([0.01, 0.025, 0.05, 0.1, 0.25, 0.5])).astype(int)}\n",
    "clf = GridSearchCV(model, parameters, scoring=\"roc_auc\", n_jobs=-1, cv=cv, verbose=0)\n",
    "clf.fit(train[[v]], train[target_var])\n",
    "print(\"Best AUC:\", clf.best_score_)\n",
    "print(\"Best params:\", clf.best_params_)\n",
    "print(\"Number of leaves:\", clf.best_estimator_.get_n_leaves())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "3a1b030f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# original data range:  [18, 95]\n",
      "# new remapped categories: 26 {3, 5, 6, 9, 11, 13, 15, 16, 21, 23, 25, 26, 28, 29, 31, 33, 35, 37, 40, 41, 42, 45, 47, 48, 49, 50}\n"
     ]
    }
   ],
   "source": [
    "# Grouping the categories into new categories (leaves) using Decision Tree\n",
    "# Here, we use the decision path, the last node is the new segment of an observation\n",
    "remap_v = [np.nonzero(r)[0].max() for r in clf.best_estimator_.decision_path(train[[v]]).toarray()]\n",
    "\n",
    "print(\"# original data range: \", [train[[v]].min().values[0], train[[v]].max().values[0]])\n",
    "print(\"# new remapped categories:\", len(set(remap_v)), set(remap_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "ff1684cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discretize variable age from [18, 95] to 26 categories\n",
      "Discretize variable campaign from [1, 56] to 7 categories\n",
      "Discretize variable pdays from [0, 999] to 3 categories\n",
      "Discretize variable previous from [0, 6] to 3 categories\n",
      "Discretize variable emp.var.rate from [-3.4, 1.4] to 8 categories\n",
      "Discretize variable cons.price.idx from [92.201, 94.767] to 14 categories\n",
      "Discretize variable cons.conf.idx from [-50.8, -26.9] to 15 categories\n",
      "Discretize variable euribor3m from [0.634, 5.045] to 45 categories\n",
      "Discretize variable nr.employed from [4963.6, 5228.1] to 9 categories\n",
      "Discretize variable age^2 from [324.0, 9025.0] to 26 categories\n",
      "Discretize variable age^3 from [5832.0, 857375.0] to 26 categories\n",
      "Discretize variable cons.conf.idx^2 from [723.6099999999999, 2580.64] to 15 categories\n",
      "Discretize variable cons.conf.idx^3 from [-131096.512, -19465.108999999997] to 15 categories\n"
     ]
    }
   ],
   "source": [
    "enable_trans_num_dt=True\n",
    "\n",
    "if enable_trans_num_dt:\n",
    "    for v in num_vars:\n",
    "        # Find the best decision tree using CV\n",
    "        cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "        model = DecisionTreeClassifier()\n",
    "        parameters = {'min_samples_leaf':(train.shape[0]*np.array([0.01, 0.025, 0.05, 0.1, 0.25, 0.5])).astype(int)}\n",
    "        clf = GridSearchCV(model, parameters, scoring=\"roc_auc\", n_jobs=-1, cv=cv, verbose=0)\n",
    "        clf.fit(train[[v]], train[target_var])\n",
    "        # Remap the variable on train, test\n",
    "        if (clf.best_score_ > 0.5) & (clf.best_estimator_.get_n_leaves() > 1):\n",
    "            print(\"Discretize variable\", v,\n",
    "                  \"from\", [train[[v]].min().values[0], train[[v]].max().values[0]],\n",
    "                  \"to\", clf.best_estimator_.get_n_leaves(), \"categories\")\n",
    "            remap_var = v + '_bin'\n",
    "            trans_vars.append(remap_var)\n",
    "            train[remap_var] = [np.nonzero(r)[0].max() for r in clf.best_estimator_.decision_path(train[[v]]).toarray()]\n",
    "            test[remap_var] = [np.nonzero(r)[0].max() for r in clf.best_estimator_.decision_path(test[[v]]).toarray()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "d1b1bd6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of bins : 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([array([18., 28., 31., 33., 36., 38., 41., 45., 49., 55., 95.])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select a num variable\n",
    "v = \"age\"\n",
    "\n",
    "# Binning values of a variable into new groups using equal frequency approach\n",
    "est = KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='quantile')\n",
    "est.fit(train[[v]])\n",
    "print(\"Number of bins :\", est.n_bins_[0])\n",
    "est.bin_edges_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "228b4073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    1246\n",
       "1.0    1606\n",
       "2.0    1444\n",
       "3.0    2075\n",
       "4.0    1303\n",
       "5.0    1533\n",
       "6.0    1745\n",
       "7.0    1554\n",
       "8.0    1855\n",
       "9.0    1639\n",
       "dtype: int64"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the binning to a variable\n",
    "binef_v = est.transform(train[[v]])\n",
    "pd.DataFrame(binef_v).value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "0aa3b8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "enable_trans_num_ef=True\n",
    "\n",
    "if enable_trans_num_ef:\n",
    "    for v in num_vars:\n",
    "        # Binning values of a variable\n",
    "        est = KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='quantile')\n",
    "        est.fit(train[[v]])\n",
    "        # Bin the variable on train, test\n",
    "        if est.n_bins_[0] > 1:\n",
    "            binef_var = v + '_binef'\n",
    "            trans_vars.append(binef_var)\n",
    "            train[binef_var] = est.transform(train[[v]])\n",
    "            test[binef_var] = est.transform(test[[v]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4225f5",
   "metadata": {},
   "source": [
    "**Finalize value transformation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "ec648198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed num, cat variables into new categorical variables : 34\n"
     ]
    }
   ],
   "source": [
    "# Finalize the variable list\n",
    "cat_vars = cat_vars + trans_vars\n",
    "print(\"Transformed num, cat variables into new categorical variables :\", len(trans_vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "b4120911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000, 59)\n",
      "(4000, 59)\n"
     ]
    }
   ],
   "source": [
    "# Arrange the data columns\n",
    "train = train[id_var + num_vars + cat_vars + target_var]\n",
    "test = test[id_var + num_vars + cat_vars + target_var]\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacaac25",
   "metadata": {},
   "source": [
    "**Value representation (cat => num)**\n",
    "\n",
    "**Categorical variable: Dummy coding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "74c99827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.])]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select a cat variable\n",
    "v = \"job\"\n",
    "\n",
    "# Build the dummy encoding on [Var194]\n",
    "enc = OneHotEncoder(drop=\"first\", handle_unknown=\"error\")\n",
    "enc.fit(pd.concat([train[[v]], test[[v]]], axis=0))\n",
    "enc.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "a66abcee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform a categorical variable\n",
    "dummy_v = enc.transform(train[[v]])\n",
    "dummy_v.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "65ad0770",
   "metadata": {},
   "outputs": [],
   "source": [
    "enable_repr_dummy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "f8371880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of variables to track the value representation process\n",
    "repr_vars = []\n",
    "dummy_vars = []\n",
    "\n",
    "if enable_repr_dummy:\n",
    "    # Create dummy variables, drop the first dummy column\n",
    "    enc = OneHotEncoder(drop=\"first\", handle_unknown=\"error\")\n",
    "    enc.fit(pd.concat([train[cat_vars], test[cat_vars]], axis=0))\n",
    "    dummy_vars = enc.get_feature_names().tolist()\n",
    "    repr_vars = repr_vars + dummy_vars\n",
    "    # Transform train, test\n",
    "    train_dummy = enc.transform(train[cat_vars])\n",
    "    test_dummy = enc.transform(test[cat_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "2f8e9c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if enable_repr_dummy:\n",
    "    # Create dummy variables, drop the first dummy column\n",
    "    enc = OneHotEncoder(drop=\"first\", handle_unknown=\"error\")\n",
    "    enc.fit(pd.concat([train[cat_vars], test[cat_vars]], axis=0))\n",
    "    dummy_vars = enc.get_feature_names().tolist()\n",
    "    repr_vars = repr_vars + dummy_vars\n",
    "    # Transform train, test\n",
    "    train_dummy = enc.transform(train[cat_vars])\n",
    "    test_dummy = enc.transform(test[cat_vars])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0191776",
   "metadata": {},
   "source": [
    "**Incidence replacement**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "aa59fd75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job</th>\n",
       "      <th>job_icd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.126708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.070113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.094203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.109557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.124889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.255539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.096661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.080392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.309091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.107995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.148352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.168067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     job   job_icd\n",
       "0    0.0  0.126708\n",
       "1    1.0  0.070113\n",
       "2    2.0  0.094203\n",
       "3    3.0  0.109557\n",
       "4    4.0  0.124889\n",
       "5    5.0  0.255539\n",
       "6    6.0  0.096661\n",
       "7    7.0  0.080392\n",
       "8    8.0  0.309091\n",
       "9    9.0  0.107995\n",
       "10  10.0  0.148352\n",
       "11  11.0  0.168067"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = \"job\"\n",
    "\n",
    "# Find the incidence rates per category of a categorical variable\n",
    "tb = pd.pivot_table(train, values=target_var, index=v, aggfunc=np.mean).reset_index()\n",
    "tb.columns = [v, v + \"_icd\"]\n",
    "tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "bddc764b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job</th>\n",
       "      <th>job_icd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.126708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.126708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.126708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.126708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.126708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   job   job_icd\n",
       "0  0.0  0.126708\n",
       "1  0.0  0.126708\n",
       "2  0.0  0.126708\n",
       "3  0.0  0.126708\n",
       "4  0.0  0.126708"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add/join the incidence variable\n",
    "pd.merge(train[[v]], tb, on=v).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "af10be68",
   "metadata": {},
   "outputs": [],
   "source": [
    "enable_repr_icd=True\n",
    "\n",
    "if enable_repr_icd:\n",
    "    for v in cat_vars:\n",
    "        # Find the incidence rates per category of a categorical variable\n",
    "        tb = pd.pivot_table(train, values=target_var, index=v, aggfunc=np.mean).reset_index()\n",
    "        icd_var = v + \"_icd\"\n",
    "        repr_vars.append(icd_var)\n",
    "        tb.columns = [v, icd_var]\n",
    "        # Add the incidence column to train, test\n",
    "        train[icd_var] = pd.merge(train[[v]], tb, on=v)[icd_var]\n",
    "        test[icd_var] = pd.merge(test[[v]], tb, on=v)[icd_var]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad36f38",
   "metadata": {},
   "source": [
    "**Weight-of-evidence conversion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "de02fb4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>subscribe</th>\n",
       "      <th>job</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>job_woe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3515</td>\n",
       "      <td>510</td>\n",
       "      <td>-1.930384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3382</td>\n",
       "      <td>255</td>\n",
       "      <td>-2.584959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>500</td>\n",
       "      <td>52</td>\n",
       "      <td>-2.263364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>382</td>\n",
       "      <td>47</td>\n",
       "      <td>-2.095273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>988</td>\n",
       "      <td>141</td>\n",
       "      <td>-1.946923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>504</td>\n",
       "      <td>173</td>\n",
       "      <td>-1.069285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>514</td>\n",
       "      <td>55</td>\n",
       "      <td>-2.234890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1407</td>\n",
       "      <td>123</td>\n",
       "      <td>-2.437031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.0</td>\n",
       "      <td>228</td>\n",
       "      <td>102</td>\n",
       "      <td>-0.804373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>2354</td>\n",
       "      <td>285</td>\n",
       "      <td>-2.111382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.0</td>\n",
       "      <td>310</td>\n",
       "      <td>54</td>\n",
       "      <td>-1.747588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11.0</td>\n",
       "      <td>99</td>\n",
       "      <td>20</td>\n",
       "      <td>-1.599388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "subscribe   job     0    1   job_woe\n",
       "0           0.0  3515  510 -1.930384\n",
       "1           1.0  3382  255 -2.584959\n",
       "2           2.0   500   52 -2.263364\n",
       "3           3.0   382   47 -2.095273\n",
       "4           4.0   988  141 -1.946923\n",
       "5           5.0   504  173 -1.069285\n",
       "6           6.0   514   55 -2.234890\n",
       "7           7.0  1407  123 -2.437031\n",
       "8           8.0   228  102 -0.804373\n",
       "9           9.0  2354  285 -2.111382\n",
       "10         10.0   310   54 -1.747588\n",
       "11         11.0    99   20 -1.599388"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select a variable\n",
    "v = \"job\"\n",
    "\n",
    "# Find the incidence rates per category of a categorical variable\n",
    "# Add +1 before calculating the log to avoid +/-Inf\n",
    "tb = train[[v] + target_var].value_counts().unstack(fill_value=0).reset_index()\n",
    "e = 1e-10  # Small value\n",
    "tb[v + \"_woe\"] = np.log((tb[1] + e) / (tb[0] + e))\n",
    "tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "a7589ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job</th>\n",
       "      <th>job_woe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.930384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.930384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.930384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.930384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.930384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   job   job_woe\n",
       "0  0.0 -1.930384\n",
       "1  0.0 -1.930384\n",
       "2  0.0 -1.930384\n",
       "3  0.0 -1.930384\n",
       "4  0.0 -1.930384"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add/join the WoE variable\n",
    "pd.merge(train[[v]], tb[[v, v + \"_woe\"]], on=v).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0caa06ca",
   "metadata": {},
   "source": [
    " **Apply value representation for all categorical variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "2bb992e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "enable_repr_woe=True\n",
    "\n",
    "if enable_repr_woe:\n",
    "    for v in cat_vars:\n",
    "        # Find the WoE per category of a categorical variable\n",
    "        tb = train[[v] + target_var].value_counts().unstack(fill_value=0).reset_index()\n",
    "        woe_var = v + \"_woe\"\n",
    "        repr_vars.append(woe_var)\n",
    "        e = 1e-10  # Small value\n",
    "        tb[woe_var] = np.log((tb[1] + e) / (tb[0] + e))\n",
    "        # Add the incidence column to train, test\n",
    "        train[woe_var] = pd.merge(train[[v]], tb[[v, woe_var]], on=v)[woe_var]\n",
    "        test[woe_var] = pd.merge(test[[v]], tb[[v, woe_var]], on=v)[woe_var]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb761ceb",
   "metadata": {},
   "source": [
    "**Finalizing value representation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "bf52384e",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cat_vars=True\n",
    "\n",
    "# Drop cat vars\n",
    "if drop_cat_vars:\n",
    "    train = train.drop(cat_vars, axis=1)\n",
    "    test = test.drop(cat_vars, axis=1)\n",
    "    cat_vars = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "8f5191f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(train.subscribe.isna().sum())\n",
    "print(test.subscribe.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7e9aa0",
   "metadata": {},
   "source": [
    "**Adding dummy variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "af2c3b12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 350)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dummy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "4a858e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "enable_repr_dummy=True\n",
    "\n",
    "if enable_repr_dummy:\n",
    "    train = pd.concat([train, pd.DataFrame(train_dummy.toarray(), columns=dummy_vars)], axis=1)\n",
    "    test = pd.concat([test, pd.DataFrame(test_dummy.toarray(), columns=dummy_vars)], axis=1)\n",
    "    del train_dummy, test_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "0caae9be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "788"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(repr_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56228085",
   "metadata": {},
   "source": [
    "**Finalize variable list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "89e2fb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_vars = num_vars+repr_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "2b864da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000, 803)\n",
      "(4000, 803)\n"
     ]
    }
   ],
   "source": [
    "# Arrange the data columns\n",
    "train = train[id_var + num_vars + cat_vars + target_var]\n",
    "test = test[id_var + num_vars + cat_vars + target_var]\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc8b595",
   "metadata": {},
   "source": [
    "**Data Normalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "42155310",
   "metadata": {},
   "outputs": [],
   "source": [
    "enable_normalize=True\n",
    "\n",
    "if enable_normalize:\n",
    "    for v in num_vars:\n",
    "        # Build the normalizer on train\n",
    "        scaler = MinMaxScaler().fit(train[[v]])\n",
    "        # Apply on train, test\n",
    "        train[v] = scaler.transform(train[[v]])\n",
    "        test[v] = scaler.transform(test[[v]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444ff217",
   "metadata": {},
   "source": [
    "**Filter out low variance variables (or constant)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "1ac1a096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop # constant vars : 0\n"
     ]
    }
   ],
   "source": [
    "# List of all predictors\n",
    "predictors = num_vars + cat_vars\n",
    "\n",
    "# Detect constant vars\n",
    "sel = VarianceThreshold(0)  # Var = 0 by default\n",
    "sel.fit(train[predictors])\n",
    "const_vars = [predictors[i] for i in np.where(sel.variances_ == 0)[0]]\n",
    "predictors = [v for v in predictors if v not in const_vars]\n",
    "\n",
    "# Drop from train, test\n",
    "print('Drop # constant vars :', len(const_vars))\n",
    "train = train.drop(const_vars, axis=1)\n",
    "test = test.drop(const_vars, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404ea9e2",
   "metadata": {},
   "source": [
    "**Drop duplicate values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "bbd6722d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# duplicated variables : 1222\n"
     ]
    }
   ],
   "source": [
    "# Count the duplicated vars\n",
    "dup_vars = train[predictors].T.duplicated()\n",
    "print('# duplicated variables :', dup_vars.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "a1c85d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the duplicated vars from train, test\n",
    "predictors = [predictors[i] for i in range(0, len(predictors)) if not dup_vars[i]]\n",
    "train = train[id_var + predictors + target_var]\n",
    "test = test[id_var + predictors + target_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "c8702af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000, 411)\n",
      "(4000, 411)\n"
     ]
    }
   ],
   "source": [
    "# Print out the data to check\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e28664",
   "metadata": {},
   "source": [
    "**Creating the BaseTable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "12afaa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_table = pd.concat([train, test]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "fe28eecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_table.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "7d629a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_table.to_csv(\"C:/Users/ngantayat1/Downloads/SML_INDIVIDUAL_PROJECT/Nandini_SML_individual_BASETABLE.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6cd61c",
   "metadata": {},
   "source": [
    "# Variable  Selection\n",
    "**Filter Methods** \n",
    "1) Correlation - Pearson, Spearman, Kendall   \n",
    "2) Fisher's Score  \n",
    "\n",
    "**Wrapper methods**   \n",
    "1) Recursive feature elimination (RFE)   \n",
    "2) Boruta\n",
    "\n",
    "**Dimensionality Reduction**\n",
    "1) Principal compnent analysis(PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "a9d9df5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create several lists to handle variables\n",
    "id_var = ['client_id']\n",
    "target_var = ['subscribe']\n",
    "predictors = [v for v in train.columns if v not in id_var + target_var]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6742a765",
   "metadata": {},
   "source": [
    "**CORRELATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "cb519a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_x = ['client_id', 'age', 'campaign', 'pdays', 'previous', 'emp.var.rate',\n",
    "       'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed', 'job',\n",
    "       'marital', 'education', 'default', 'housing', 'loan', 'contact',\n",
    "       'month', 'day_of_week', 'poutcome', 'age_na', 'campaign_na', 'pdays_na',\n",
    "       'previous_na', 'emp.var.rate_na', 'cons.price.idx_na',\n",
    "       'cons.conf.idx_na', 'euribor3m_na', 'nr.employed_na']\n",
    "\n",
    "p_y = 'subscribe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "a553afc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get corelation based on Kendall, Pearson and Spearman's score\n",
    "def kendall_pval(x,y):\n",
    "    return kendalltau(x,y)[1]\n",
    "\n",
    "def pearsonr_pval(x,y):\n",
    "    return pearsonr(x,y)[1]\n",
    "\n",
    "def spearmanr_pval(x,y):\n",
    "    return spearmanr(x,y)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "fec9e7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_p = train.corr(method=pearsonr_pval)\n",
    "corr_s = train.corr(method=spearmanr_pval)\n",
    "corr_k = train.corr(method=kendall_pval) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "402b8a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get top variables based on the cutoff of 70%\n",
    "cutoff = .7\n",
    "cp_cols = corr_p[corr_p[\"subscribe\"]>cutoff].index\n",
    "cs_cols = corr_s[corr_s[\"subscribe\"]>cutoff].index\n",
    "ck_cols = corr_k[corr_k[\"subscribe\"]>cutoff].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "d63ea32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "cor_cols = list(set(cp_cols) & set(cs_cols) & set(ck_cols))\n",
    "cor_cols.remove('subscribe')\n",
    "print(len(cor_cols))\n",
    "\n",
    "p_f_cols = list(cor_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "b34980df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x5_2.0', 'x2_3.0', 'x26_27', 'x29_45', 'x0_3.0', 'x28_11']"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cor_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afde29b",
   "metadata": {},
   "source": [
    "**Fisher's Score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cf63e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FisherScore(bt, target_var, predictors):\n",
    "    \"\"\"\n",
    "    This function calculate the Fisher score of a variable.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the unique values of dependent variable\n",
    "    target_var_val = bt[target_var].unique()\n",
    "    # Calculate FisherScore for each predictor\n",
    "    predictor_FisherScore = []\n",
    "    for v in predictors:\n",
    "        fs = np.abs(np.mean(bt.loc[bt[target_var]==target_var_val[0], v]) - np.mean(bt.loc[bt[target_var]==target_var_val[1], v])) / \\\n",
    "             np.sqrt(np.var(bt.loc[bt[target_var]==target_var_val[0], v]) + np.var(bt.loc[bt[target_var]==target_var_val[1], v]))\n",
    "        predictor_FisherScore.append(fs)\n",
    "    return predictor_FisherScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c172e8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Fisher Score for all variable\n",
    "fs = FisherScore(train, target_var[0], predictors)\n",
    "fs_df = pd.DataFrame({\"predictor\":predictors, \"fisherscore\":fs})\n",
    "fs_df[\"fisherscore2\"] = fs_df.fisherscore.astype(str).str.extract(r' (.*)')\n",
    "fs_df[\"fisher_merged\"] = np.where(fs_df.fisherscore2.isna(),fs_df.fisherscore, fs_df.fisherscore2)\n",
    "fs_df = fs_df.drop([\"fisherscore2\", \"fisherscore\"], axis=1)\n",
    "fs_df.columns = [\"predictor\", \"fisherscore\"]\n",
    "fs_df.fisherscore = fs_df.fisherscore.astype(float)\n",
    "fs_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca44aaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_df = fs_df.sort_values('fisherscore', ascending=False).reset_index(drop=True)\n",
    "fs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b179006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the Fisher Score\n",
    "plt.plot(fs_df['fisherscore'].values.squeeze())\n",
    "plt.axvline(x=40, linestyle='dashed', color='red')\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel(str(fs_df.shape[0]) + ' predictors')\n",
    "plt.ylabel('Fisher Score')\n",
    "plt.legend(['Fisher Score', 'Top20'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40867dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how AUC change when add more variables: Top n vars\n",
    "fs_scores = []\n",
    "top_n_vars = 50\n",
    "for i in range(1, top_n_vars+1):\n",
    "    if i % 100 == 0: print('Added # top vars :', i)\n",
    "    top_n_predictors = fs_df['predictor'][:i]\n",
    "    clf = LogisticRegression()\n",
    "    fs_scores.append(cross_validate(clf, train[top_n_predictors], train[target_var].values.squeeze(),\n",
    "                                    scoring='roc_auc', cv=5, verbose=0, n_jobs=-1, return_train_score=True))\n",
    "\n",
    "# How the AUC curve looks like when adding top vars\n",
    "plt.plot([s['train_score'].mean() for s in fs_scores], color='blue')\n",
    "plt.plot([s['test_score'].mean() for s in fs_scores], color='red')\n",
    "plt.xlabel('# vars')\n",
    "plt.ylabel('AUC')\n",
    "plt.legend(['train', 'test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80175a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the top variables based on Fisher Score\n",
    "n_top_fs_vars = 35  # Top FS vars\n",
    "top_fs_vars = fs_df['predictor'].values[:n_top_fs_vars]\n",
    "print(\"Selected # vars :\", len(top_fs_vars))\n",
    "top_fs_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc36716",
   "metadata": {},
   "source": [
    "**RFE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "30265575",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection_rfe(X, y, estimators):\n",
    "    selected_features = {}\n",
    "    for estimator in estimators:\n",
    "        rfe = RFE(estimator, n_features_to_select=10)\n",
    "        rfe.fit(X, y)\n",
    "        selected_features[str(estimator)] = list(X.columns[rfe.support_])\n",
    "    return selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b2f058",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [LogisticRegression(), RandomForestClassifier(), LinearSVC(), GradientBoostingClassifier(), MLPClassifier()]\n",
    "\n",
    "selected_features = feature_selection_rfe(train[predictors], train[target_var], estimators)\n",
    "\n",
    "for estimator_name, feature_names in selected_features.items():\n",
    "    print(estimator_name + ':', feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29bfcad",
   "metadata": {},
   "source": [
    "**BORUTA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68eda23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9bf159",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f104365c",
   "metadata": {},
   "source": [
    "**PCA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532aa91b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dee379b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf378bb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "adca6a55",
   "metadata": {},
   "source": [
    "# MODELS  \n",
    "1. Logistic regression\n",
    "2. Random forest\n",
    "3. SVM\n",
    "4. GBM\n",
    "5. Neural network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606ea1f0",
   "metadata": {},
   "source": [
    "**Benchmarking models with all predictors and no parameter tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa90610",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic     = LogisticRegression()\n",
    "randomForest = RandomForestClassifier()\n",
    "SVM          = LinearSVC()\n",
    "GBM          = GradientBoostingClassifier()\n",
    "NeuralNet    = MLPClassifier()\n",
    "\n",
    "\n",
    "\n",
    "# create a dict to loop through the models later on\n",
    "models = {\n",
    "          \"Logistic Regression\"     :logistic,\n",
    "          \"Random Forest\"           :randomForest,\n",
    "          \"SVM \"                    :SVC,\n",
    "          \"GBM\"                     :GBM,\n",
    "          \"NN\"                      :MLP\n",
    "\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79acdab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_all = train[predictors]\n",
    "train_y     = train[target_var].values.ravel()\n",
    "\n",
    "for model in models:\n",
    "    random.seed=42\n",
    "    models[model].fit(train_x_all, train_y)\n",
    "    print(f\"{model} has been trained successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71eca323",
   "metadata": {},
   "outputs": [],
   "source": [
    "performances = {}\n",
    "\n",
    "for model in models:\n",
    "    %time\n",
    "    random.seed=42\n",
    "    predictions   = models[model].predict(test_x_all)\n",
    "    probabilities = pd.DataFrame(models[model].predict_proba(test_x_all))[1]\n",
    "    accuracy      = accuracy_score(test_y,predictions)\n",
    "    auc           = roc_auc_score(np.array(test_y),np.array(probabilities))\n",
    "    print(f\"{model} completed.\")\n",
    "    \n",
    "    performances[model] = {\"Test_Accuracy\":accuracy,\"Test_AUC\":auc}\n",
    "\n",
    "test_perf = pd.DataFrame(performances).transpose().sort_values(by=\"Test_AUC\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98552f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_all_vars = train_perf.merge(test_perf, left_index=True, right_index=True)\n",
    "perf_all_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c59724f",
   "metadata": {},
   "source": [
    "**Benchmarking models based on feature selection**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b687af14",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b44e92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56c097ff",
   "metadata": {},
   "source": [
    "# Evaluation metric    \n",
    "\n",
    "1.AUC  \n",
    "2.Accuracy  \n",
    "3.Confusion matrix  \n",
    "4.F1 score, precision and recall  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170a1de6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664fa25b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
